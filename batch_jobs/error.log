2018-11-27 19:54:09.811601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla K20Xm major: 3 minor: 5 memoryClockRate(GHz): 0.732
pciBusID: 0000:08:00.0
totalMemory: 5.57GiB freeMemory: 5.49GiB
2018-11-27 19:54:09.811660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2018-11-27 19:54:10.217597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-11-27 19:54:10.217654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2018-11-27 19:54:10.217666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2018-11-27 19:54:10.217949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5278 MB memory) -> physical GPU (device: 0, name: Tesla K20Xm, pci bus id: 0000:08:00.0, compute capability: 3.5)
Using TensorFlow backend.
2018-11-28 03:12:38.339581: E tensorflow/stream_executor/cuda/cuda_driver.cc:397] failed call to cuInit: CUDA_ERROR_NO_DEVICE
2018-11-28 03:12:38.339764: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] retrieving CUDA diagnostic information for host: node04
2018-11-28 03:12:38.339791: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:170] hostname: node04
2018-11-28 03:12:38.339931: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:194] libcuda reported version is: 384.81.0
2018-11-28 03:12:38.340118: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:198] kernel reported version is: 384.81.0
2018-11-28 03:12:38.340151: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:305] kernel version seems to match DSO: 384.81.0
Using TensorFlow backend.
